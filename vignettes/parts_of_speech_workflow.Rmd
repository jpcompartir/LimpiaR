---
title: "LimpiaR X Parts of Speech Workflow"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{processing_parts_of_speech}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---
In this vignette we'll be looking at how to use LimpiaR to process a text variable for its parts of speech via {udpipe}. For a primer on parts of speech see [Parts of Speech Wikipedia](https://en.wikipedia.org/wiki/Part_of_speech)

The main motivation for processing and extraction parts of speech is to home in on the particular aspects of language which are most informative for answering a given research question. For example, if you want to know what people think about something, you might focus on adjectives and nouns. If you want to know how people are using something, you might focus more on verbs/phrasal verbs.

Before we start, we must ensure that we have the necessary libraries installed and loaded, including LimpiaR, and a few others for wrangling purposes.
```{r}
library(LimpiaR)
library(tibble)
library(dplyr)
library(stringr)
```

First, we must select what model it is that that we want to download. UDPipe pre-trained models build upon  Universal Dependencies treebanks and are made available for more than 65 languages based on 101 treebanks. For the purpose of this documentation, we will select the `english` model.

Using `limpiar_pos_download_model()`, we can select the `language` we want the model to be trained on, the directory or folder we want to save the model whether locally or on a drive using the `model_directory` argument and inputting a string pointing to a specific directory. For this example, lets imagine that we want to create a file in 'Documents' called 'saved_model' and save the model there, the model will look something like this 'english-ewt-ud-2.5-191206.udpipe'. There remains one more argument, and that is `overwrite`, which is set to `TRUE` by default meaning it will download the model and overwrite the file if the file already existed. If set to `FALSE`, the model will only be downloaded if it does not already exist on disk.

```{r}
model <- limpiar_pos_download_model(language = "english", model_directory = "~/Documents/saved_model", overwrite = TRUE)
```

Now we have a model downloaded and saved somewhere that suits us, we can now load this model in anytime with the help of `limpiar_pos_load_model()`, that simply takes in the same path provided when downloading the model using the `model_directory` argument. There are two ways to feed this information to the function.
```{r}
model_loaded <- limpiar_pos_load_model(model_directory = "~/Documents/saved_model/english-ewt-ud-2.5-191206.udpipe")
```
OR
```{r}
# this approach will only work if the 'model' object is still loaded into memory(appearing in the Environment pane of Rstudio)
model_loaded <- limpiar_pos_load_model(model_directory = model$file_model) 
```


It's worth noting that before annotating, we must ensure that the model we want to use is not the object we create with `limpiar_pos_download_model()` but the loaded model using `limpiar_pos_load_model()` otherwise the user will be met with error message:

'Error in limpiar_pos_annotate(saved_model = model, texts = data$text,  : 
  saved_model should be of class udpipe_model as returned by the function limpiar_pos_load_model'
  
For example, lets use the data object derived from {stringr} package containing sentences ideal for tagging, tokenizing, lemmatizing and parsing for parts of speech analysis.
```{r}
data <- dplyr::tibble(text = tolower(stringr::sentences[1:100]), document = 1:100)
```

Now we have our data and we should have our loaded model, we can begin annotating with the `limpiar_pos_annotate()` function. 

It's worth noting that the output is dependent on cleaning steps performed on texts before annotating. For example, it is possible that with the removal of punctuation the dependency parsing bits of the function may under-perform. This could also be said for the POS tagging process as nouns(PRON) and proper-nouns(PROPN) will be harder to differentiate.

When using LimpiaR's annotate function we tokenize all sentences of our text variable(text_var) within a selected data frame or tibble(data), enabling us to perform Parts of Speech tagging, lemmatization and dependency parsing(parse_text). We can also speed the process up by calling TRUE on the parallel processing argument(in_parallel).

```{r}
annotations <- limpiar_pos_annotate(data = data, text_var = text, saved_model = model_loaded, in_parallel = FALSE, parse_text = TRUE)
```

